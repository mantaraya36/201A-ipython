{
 "metadata": {
  "name": "",
  "signature": "sha256:084328e4a630980cbf0254bd16cef7456c305c1b27736c106951a6eb80dc4370"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcParams['figure.figsize'] = (16, 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Matching"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Brute-force"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From http://docs.opencv.org/trunk/doc/py_tutorials/py_feature2d/py_matcher/py_matcher.html#matcher"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(0)\n",
      "\n",
      "while (True):\n",
      "    ret, frame = cap.read()\n",
      "    cv2.imshow('frame',frame)\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n",
      "\n",
      "cap.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img1 = frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(0)\n",
      "\n",
      "while (True):\n",
      "    ret, frame = cap.read()\n",
      "    cv2.imshow('frame',frame)\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n",
      "\n",
      "cap.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img2 = frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#orb = cv2.ORB()\n",
      "detector = cv2.FeatureDetector_create(\"ORB\")\n",
      "descriptorExtractor = cv2.DescriptorExtractor_create(\"ORB\")\n",
      "keypoints = detector.detect(img1)\n",
      "(keypoints, descriptors) = descriptorExtractor.compute(img1, keypoints)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(keypoints), len(keypoints)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keypoints[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(keypoints[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keypoints[0].pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "points = [kp.pt for kp in keypoints]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "points[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip(*points)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scatter(*zip(*points))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imshow(img1[:,:,::-1])\n",
      "scatter(*zip(*points))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "descriptors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "descriptors.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keypoints2 = detector.detect(img2)\n",
      "(keypoints2, descriptors2) = descriptorExtractor.compute(img1, keypoints2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "descriptors2.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "points2 = [kp.pt for kp in keypoints2]\n",
      "subplot(121)\n",
      "imshow(img1[:,:,::-1])\n",
      "scatter(*zip(*points))\n",
      "subplot(122)\n",
      "imshow(img2[:,:,::-1])\n",
      "scatter(*zip(*points2))\n",
      "\n",
      "gcf().set_figheight(8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now the matching:\n",
      "http://docs.opencv.org/modules/features2d/doc/common_interfaces_of_descriptor_matchers.html#descriptormatcher-create"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create BFMatcher object\n",
      "\n",
      "bf = cv2.DescriptorMatcher_create(\"BruteForce-Hamming\")\n",
      "#bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
      "\n",
      "# Match descriptors.\n",
      "matches = bf.match(descriptors,descriptors2)\n",
      "# Sort them in the order of their distance.\n",
      "matches = sorted(matches, key = lambda x:x.distance)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(matches), type(matches[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(matches[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches[0].distance, matches[0].imgIdx, matches[0].queryIdx, matches[0].trainIdx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches_src = [keypoints[match.queryIdx].pt for match in matches]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imshow(img1[:,:,::-1])\n",
      "scatter(*zip(*matches_src))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(keypoints2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches_dest = [keypoints2[match.trainIdx].pt for match in matches]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(matches_dest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imshow(img2[:,:,::-1])\n",
      "scatter(*zip(*matches_dest))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twoimg = r_[img1, img2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imshow(twoimg[:,:,::-1])\n",
      "gcf().set_figheight(8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot( ((5,0), (10,15)) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot( (5,0), (10,15))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches_src[:5], matches_dest[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip(matches_src[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip(*matches_src[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(5):\n",
      "    print zip(matches_src[i],matches_dest[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(5):\n",
      "    plot(*zip(matches_src[i],matches_dest[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imshow(twoimg[:,:,::-1])\n",
      "gcf().set_figheight(8)\n",
      "\n",
      "scatter(*zip(*matches_src[:5]))\n",
      "scatter(*zip(*matches_dest[:5]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches_dest[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "array(matches_dest[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "array(matches_dest[:5])[:,1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transpoints = array(matches_dest[:5])\n",
      "\n",
      "transpoints[:,1] +=100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transpoints"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nice! Automatic passing by reference."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imshow(twoimg[:,:,::-1])\n",
      "gcf().set_figheight(8)\n",
      "\n",
      "for i in range(50):\n",
      "    shifted_point = array(matches_dest[i])\n",
      "    shifted_point[1] += 480\n",
      "    plot(*zip(matches_src[i],shifted_point))\n",
      "\n",
      "\n",
      "xlim((0, 640))\n",
      "ylim((960, 0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Tracking"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Mean-Shift"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://docs.opencv.org/trunk/doc/py_tutorials/py_video/py_meanshift/py_meanshift.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#cap = cv2.VideoCapture('slow.flv')\n",
      "cap = cv2.VideoCapture(0)\n",
      "\n",
      "# take first frame of the video\n",
      "ret,frame = cap.read()\n",
      "\n",
      "# setup initial location of window\n",
      "r,h,c,w = 170,150,250,150  # simply hardcoded the values\n",
      "track_window = (c,r,w,h)\n",
      "\n",
      "# set up the ROI for tracking\n",
      "roi = frame[r:r+h, c:c+w]\n",
      "hsv_roi =  cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
      "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
      "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
      "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
      "\n",
      "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
      "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
      "\n",
      "while(1):\n",
      "    ret ,frame = cap.read()\n",
      "\n",
      "    if ret == True:\n",
      "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
      "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
      "\n",
      "        # apply meanshift to get the new location\n",
      "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
      "\n",
      "        # Draw it on image\n",
      "        x,y,w,h = track_window\n",
      "        cv2.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
      "        cv2.imshow('frame',frame)\n",
      "\n",
      "        k = cv2.waitKey(60) & 0xff\n",
      "        if k == 27:\n",
      "            break\n",
      "        #else:\n",
      "        #    cv2.imwrite(chr(k)+\".jpg\",img2)\n",
      "\n",
      "    else:\n",
      "        break\n",
      "\n",
      "#cv2.destroyAllWindows()\n",
      "cap.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "CamShift"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(0)\n",
      "\n",
      "# take first frame of the video\n",
      "ret,frame = cap.read()\n",
      "\n",
      "# setup initial location of window\n",
      "r,h,c,w = 320,90,400,125  # simply hardcoded the values\n",
      "track_window = (c,r,w,h)\n",
      "\n",
      "# set up the ROI for tracking\n",
      "roi = frame[r:r+h, c:c+w]\n",
      "hsv_roi =  cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
      "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
      "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
      "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
      "\n",
      "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
      "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
      "\n",
      "while(1):\n",
      "    ret ,frame = cap.read()\n",
      "\n",
      "    if ret == True:\n",
      "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
      "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
      "\n",
      "        # apply meanshift to get the new location\n",
      "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
      "\n",
      "        # Draw it on image\n",
      "        \n",
      "        x,y,w,h = track_window\n",
      "        cv2.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
      "        #pts = cv2.boxPoints(ret)\n",
      "        #pts = np.int0(pts)\n",
      "        #pts = array(ret[0])\n",
      "        #cv2.polylines(frame,[pts],True, 255,2)\n",
      "        cv2.imshow('frame',frame)\n",
      "\n",
      "        k = cv2.waitKey(60) & 0xff\n",
      "        if k == 27:\n",
      "            break\n",
      "        #else:\n",
      "            #cv2.imwrite(chr(k)+\".jpg\",img2)\n",
      "\n",
      "    else:\n",
      "        break\n",
      "\n",
      "#cv2.destroyAllWindows()\n",
      "cap.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By: Andr\u00e9s Cabrera mantaraya36@gmail.com\n",
      "\n",
      "For Course MAT 201A at UCSB\n",
      "\n",
      "This ipython notebook is licensed under the CC-BY-NC-SA license: http://creativecommons.org/licenses/by-nc-sa/4.0/\n",
      "\n",
      "![http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png](http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}